from openai import OpenAI
from .openai_client import OpenAI_Client

models = [
    "360gpt-pro",
    "360GPT_S2_V9",
    "claude-3-haiku-20240307",
    "claude-3-opus-20240229",
    "claude-3-sonnet-20240229",
    "code-llama-13b",
    "code-llama-34b",
    "code-llama-7b",
    "deepseek-chat",
    "deepseek-coder",
    "ERNIE-3.5-4K-0205",
    "ERNIE-3.5-8K",
    "ERNIE-3.5-8K-0205",
    "ERNIE-3.5-8K-0329",
    "ERNIE-3.5-8K-1222",
    "ERNIE-3.5-8K-Preview",
    "ERNIE-4.0-8K",
    "ERNIE-4.0-8K-0104",
    "ERNIE-4.0-8K-0329",
    "ERNIE-4.0-8K-Preview",
    "ERNIE-4.0-8K-Preview-0518",
    "ERNIE-Lite-8K-0922",
    "ERNIE-Speed-128K",
    "ERNIE-Speed-8K",
    "ERNIE-Tiny-8K",
    "gemini-1.0-pro",
    "gemini-1.0-pro-001",
    "gemini-1.0-pro-latest",
    "gemini-1.5-flash",
    "gemini-1.5-flash-latest",
    "gemini-1.5-pro",
    "gemini-1.5-pro-latest",
    "gemini-pro",
    "glm-3-turbo",
    "glm-4",
    "glm-4-0520",
    "glm-4-air",
    "glm-4-airx",
    "glm-4-flash",
    "glm-4v",
    "google-palm",
    "gpt-4",
    "gpt-4-0314",
    "gpt-4-0613",
    "gpt-4-32k",
    "gpt-4-32k-0314",
    "gpt-4-32k-0613",
    "gpt-4-all",
    "gpt-4-dalle",
    "gpt-4-vision-preview",
    "gpt-4o",
    "gpt-4o-mini",
    "gpt-4o-2024-05-13",
    "gpt-4o-all",
    "hunyuan",
    "llama-2-13b",
    "llama-2-70b",
    "llama-2-7b",
    "mixtral-8x7b",
    "mixtral-8x7b-32768",
    "moonshot-v1-128k",
    "moonshot-v1-32k",
    "moonshot-v1-8k",
    "qwen-1.8b-chat",
    "qwen-14b-chat",
    "qwen-72b-chat",
    "qwen-7b-chat",
    "qwen-long",
    "qwen-max",
    "qwen-max-0107",
    "qwen-max-0403",
    "qwen-max-0428",
    "qwen-max-1201",
    "qwen-max-longcontext",
    "qwen-plus",
    "qwen-turbo",
    "qwen1.5-0.5b-chat",
    "qwen1.5-110b-chat",
    "qwen1.5-14b-chat",
    "qwen1.5-32b-chat",
    "qwen1.5-72b-chat",
    "qwen1.5-7b-chat",
    "search-gpts",
    "search-gpts-chat",
    "SparkDesk-v1.1",
    "SparkDesk-v2.1",
    "SparkDesk-v3.1",
    "SparkDesk-v3.5",
    "yi-large",
    "yi-large-rag",
    "yi-large-turbo",
    "yi-medium",
    "yi-medium-200k",
    "yi-spark",
    "yi-vision",
    "gpt-4o-2024-11-20",
    "claude-3-5-sonnet-20241022",
    "net-llama-3.1-70b",
    "deepseek-r1",
    "net-llama-3.1-8b",
    "qwen2.5-7b-instruct",
    "gpt-4o-mini-2024-07-18",
    "llama-3.1-70b",
    "llama-3.1-8b",
]

support_models = {i:i for i in models}



class Next_Client(OpenAI_Client):
    def __init__(
        self,
        model: str = "gpt-4-turbo",
        api_config: dict = None,
        max_requests_per_minute=20,
        request_window=20,
    ):
        super().__init__(model, api_config, max_requests_per_minute, request_window)
        self.client_name = "Next"
        self.client = OpenAI(
            base_url=self.api_config["NEXT_BASE_URL"],
            api_key=self.api_config["NEXT_API_KEY"],
        )
        self.support_models = support_models
